{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-muscle",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "- Python3.7\n",
    "- Tesnorflow (`pip install tensorflow`)\n",
    "- Tensorflow Dataset (`pip install tensorflow_datasets`)\n",
    "- Requsets (`pip install requests`)\n",
    "- Easytensor (`pip install easytensor`)\n",
    " ###### Note: this was adapted from https://www.tensorflow.org/datasets/keras_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instant-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorlfow (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for tensorlfow\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/home/kamal/python3.7/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorlfow tensorflow_datasets requests easytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "christian-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easytensor\n",
    "import tensorflow\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "guilty-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "advised-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "social-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elect-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 4s 3ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.1935 - val_sparse_categorical_accuracy: 0.9437\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1844 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1429 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9629 - val_loss: 0.1159 - val_sparse_categorical_accuracy: 0.9653\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9701\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9731\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0805 - val_sparse_categorical_accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7b1c2ab490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gothic-blocking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path: /home/kamal/repos/python-client/my_model\n",
      "INFO:tensorflow:Assets written to: /home/kamal/repos/python-client/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/kamal/repos/python-client/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "export_path = os.path.join(os.getcwd(), \"my_model\")\n",
    "print(\"export_path: {}\".format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "median-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token is expired. Please reauthenticate.\n",
      "Username: kamal@easytensor.com\n",
      "Password: ········\n"
     ]
    }
   ],
   "source": [
    "model_id, access_token = easytensor.upload_model(\"MNIST Model\", export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "executed-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bd047e70-8f71-46c2-a7cc-2b471fca1bcb 6212cc64-7715-4476-87e3-81a40c101021\n"
     ]
    }
   ],
   "source": [
    "print(model_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fancy-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[ -1.2014357   -4.0958157   -4.5260525  ... -11.852829     3.5192845\n",
      "   -7.229445  ]\n",
      " [ -6.1490326   -5.7538395   -5.7007556  ...   8.986236    -1.8156674\n",
      "   -0.31361133]\n",
      " [ -8.624191    -3.296017    -0.01982616 ...  10.833549    -3.1925135\n",
      "   -4.4252543 ]\n",
      " ...\n",
      " [ -3.924925    -2.612865    -1.5709325  ...  -7.6606817    0.26862323\n",
      "  -10.600916  ]\n",
      " [ -6.3767066   -0.8413291    1.1254566  ...   6.730558    -3.446644\n",
      "   -4.3622684 ]\n",
      " [ -2.3230085   -5.990632    -4.2682247  ...   0.86786187  -5.0251307\n",
      "    0.9918482 ]]\n"
     ]
    }
   ],
   "source": [
    "for a, b in ds_train:\n",
    "    print(type(a), type(b))\n",
    "    result = model.predict(a)\n",
    "    print(model.predict(a))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "formed-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(map(lambda x: x[0], ds_train))\n",
    "labels = list(map(lambda x: x[1], ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "genetic-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "0.9820359281437125\n"
     ]
    }
   ],
   "source": [
    "unbatched = ds_train.unbatch()\n",
    "import numpy as np\n",
    "correct = wrong = 0\n",
    "f = 0\n",
    "for image, label in unbatched.as_numpy_iterator():\n",
    "#     print(image.flatten().shape)\n",
    "#     print(image.shape)\n",
    "    f += 1 \n",
    "    if f %100 == 0:\n",
    "        print(f)\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))\n",
    "    num = 0\n",
    "    max_pre = 0\n",
    "    for i, n in enumerate(prediction[0]):\n",
    "        if n > max_pre:\n",
    "            num = i\n",
    "            max_pre = n\n",
    "    if num == label:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    if f > 500:\n",
    "        break\n",
    "\n",
    "print((correct)/(correct+wrong))\n",
    "#     numpy_images, numpy_labels = example[\"image\"], example[\"label\"]\n",
    "#     print(numpy_images.shape)\n",
    "# print(len(numpy_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "local-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.post(\n",
    "    \"https://app.easytensor.com:443/query/\",\n",
    "    json={\n",
    "        \"instances\": [\n",
    "            b[0][1].numpy().flatten().tolist()\n",
    "        ]\n",
    "    },\n",
    "    headers={\"Authentication\": \"Bearer {}\".format(access_token)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "removable-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\r\\n<head><title>502 Bad Gateway</title></head>\\r\\n<body>\\r\\n<center><h1>502 Bad Gateway</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.ok\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "subject-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbatched = ds_train.unbatch()\n",
    "# a = list(unbatched)\n",
    "print(len(a))\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "casual-connectivity",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-6e8c5bc6236d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# b[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "b = a[:1]\n",
    "# b[0]\n",
    "print(b[0][0].flatten().shape)\n",
    "print(b[0][1])\n",
    "model.predict(np.expand_dims(b[0][0], axis=0))\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
