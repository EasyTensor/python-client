{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polar-muscle",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "- Python3.5-3.8\n",
    "- Tesnorflow (`pip install tensorflow`)\n",
    "- Tensorflow Dataset (`pip install tensorflow_datasets`)\n",
    "- Requsets (`pip install requests`)\n",
    "- Easytensor (`pip install easytensor`)\n",
    "- Matplotlib (`pip install matplotlib`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow tensorflow_datasets requests easytensor matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-patient",
   "metadata": {},
   "source": [
    "# Train a simple MNIST model\n",
    "Here, we will train a simple model that can classify english digits from 1 to 9. The MNIST dataset is made up of small images that are 28x28 pixels.\n",
    "\n",
    "The full explanation of how this model is trained can be found [here](https://www.tensorflow.org/datasets/keras_example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guilty-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-biography",
   "metadata": {},
   "source": [
    "#### Visualizing the data\n",
    "The data is made up of batches of small digit images from 0 to 9. Here is an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "existing-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of image batches: 469\n",
      "Each batch contains 128 images\n",
      "Each image has shape (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "image_label_tuples = list(map(lambda x: (x[0], x[1]), ds_train)) \n",
    "image_batches = list(map(lambda x: x[0], image_label_tuples)) # shape (x, 128, 28, 28, 1)\n",
    "label_batches = list(map(lambda x: x[1], image_label_tuples)) # shape (x, 128, 1)\n",
    "print(\"number of image batches:\", len(image_batches))\n",
    "print(\"Each batch contains\", image_batches[0].shape[0], \"images\")\n",
    "print(\"Each image has shape\", image_batches[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rural-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image to send:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure\n",
    "plt.imshow(image_batches[0][0], cmap='gray')\n",
    "print(\"Image to send:\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "social-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elect-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6211 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.1925 - val_sparse_categorical_accuracy: 0.9451\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1731 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.1355 - val_sparse_categorical_accuracy: 0.9590\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.1128 - val_sparse_categorical_accuracy: 0.9661\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9702\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0768 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0951 - val_sparse_categorical_accuracy: 0.9704\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9804 - val_loss: 0.0798 - val_sparse_categorical_accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16c164580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128,activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gothic-blocking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path: /Users/kamalkamalaldin/repos/python-client/docs/examples/my_model\n",
      "INFO:tensorflow:Assets written to: /Users/kamalkamalaldin/repos/python-client/docs/examples/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/kamalkamalaldin/repos/python-client/docs/examples/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "export_path = os.path.join(os.getcwd(), \"my_model\")\n",
    "print(\"export_path: {}\".format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-romania",
   "metadata": {},
   "source": [
    "# Upload to EasyTensor\n",
    "Now that we have the model exported, we can upload it to cloud and have EasyTensor serve it for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "median-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token is expired. Please reauthenticate.\n",
      "Username: kamal@easytensor.com\n",
      "Password: ········\n"
     ]
    }
   ],
   "source": [
    "import easytensor\n",
    "# easytensor.set_base_url(\"http://app.easytensor.com/\")\n",
    "model_id, access_token = easytensor.upload_model(\"Showing Joe the Model\", export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-stuff",
   "metadata": {},
   "source": [
    "That's it! The model is now in the cloud with one line of code. Each model will have an ID and an access token. Anyone with the access token can send requests to the model, so make sure you store it somewhere safe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "executed-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ID: c13e0901-9237-42b3-98f9-99bad2353c2d\n",
      "access token: 0c485831-d746-41f7-8760-cb48c8b514eb\n"
     ]
    }
   ],
   "source": [
    "print(\"model ID:\", model_id)\n",
    "print(\"access token:\", access_token)\n",
    "access_token=\"068b3952-dc5c-4606-9c09-af1070e7f32f\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-performance",
   "metadata": {},
   "source": [
    "# Use the model\n",
    "Now let's try to use the model via a simple http request. We will use a random image from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "formed-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of image batches: 469\n",
      "Each batch contains 128 images\n",
      "Each image has shape (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# We need to get the label and image in the same iterator to get around shuffling.\n",
    "image_label_tuples = list(map(lambda x: (x[0], x[1]), ds_train)) \n",
    "image_batches = list(map(lambda x: x[0], image_label_tuples)) # shape (x, 128, 28, 28, 1)\n",
    "label_batches = list(map(lambda x: x[1], image_label_tuples)) # shape (x, 128, 1)\n",
    "print(\"number of image batches:\", len(image_batches))\n",
    "print(\"Each batch contains\", image_batches[0].shape[0], \"images\")\n",
    "print(\"Each image has shape\", image_batches[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "settled-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image to send:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure\n",
    "plt.imshow(image_batches[0][0], cmap='gray')\n",
    "print(\"Image to send:\")\n",
    "plt.show()\n",
    "\n",
    "image_to_predict = image_batches[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "controlled-bradley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from server:\n",
      "{\"predictions\":[[-10.4388409,5.0249939,-2.20620871,0.580625176,-3.66463208,-2.8926208,-6.41355,0.908852458,0.395605326,-0.766769]]}\n",
      "{'predictions': [[-10.4388409,\n",
      "                  5.0249939,\n",
      "                  -2.20620871,\n",
      "                  0.580625176,\n",
      "                  -3.66463208,\n",
      "                  -2.8926208,\n",
      "                  -6.41355,\n",
      "                  0.908852458,\n",
      "                  0.395605326,\n",
      "                  -0.766769]]}\n",
      "Digit prediction:  [1]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import requests\n",
    "import numpy as np\n",
    "access_token=\"068b3952-dc5c-4606-9c09-af1070e7f32f\"\n",
    "response = requests.post(\n",
    "    \"https://app.easytensor.com/query/\",\n",
    "    json={\n",
    "        \"instances\": [\n",
    "            # use the first picture of the first batch\n",
    "            # make it a serializable list\n",
    "            image_to_predict.numpy().tolist()\n",
    "        ]\n",
    "    },\n",
    "    headers={\"accessToken\": access_token}\n",
    ")\n",
    "print(\"Response from server:\")\n",
    "print(response.text)\n",
    "pprint(response.json())\n",
    "print(\"Digit prediction: \", np.array(response.json()[\"predictions\"]).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "genuine-sender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4470588266849518], [0.9921568632125854], [0.9921568632125854], [0.572549045085907], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4431372582912445], [0.9882352948188782], [0.9882352948188782], [0.9764705896377563], [0.8823529481887817], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4431372582912445], [0.9882352948188782], [0.9882352948188782], [0.9882352948188782], [0.9882352948188782], [0.43529412150382996], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4431372582912445], [0.7019608020782471], [0.4745098054409027], [0.9882352948188782], [0.9882352948188782], [0.8470588326454163], [0.07058823853731155], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.19607843458652496], [0.0470588244497776], [0.09803921729326248], [0.8039215803146362], [0.9882352948188782], [0.9921568632125854], [0.4156862795352936], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.6627451181411743], [0.9921568632125854], [1.0], [0.658823549747467], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.47843137383461], [0.9882352948188782], [0.9921568632125854], [0.9529411792755127], [0.19607843458652496], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.11372549086809158], [0.9882352948188782], [0.9921568632125854], [0.9882352948188782], [0.21568627655506134], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.11372549086809158], [0.9882352948188782], [0.9921568632125854], [0.9882352948188782], [0.21568627655506134], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.05098039284348488], [0.7411764860153198], [0.9921568632125854], [0.9882352948188782], [0.5215686559677124], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5529412031173706], [1.0], [0.9921568632125854], [0.7686274647712708], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5490196347236633], [0.9921568632125854], [0.9882352948188782], [0.7647058963775635], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.5490196347236633], [0.9921568632125854], [0.9882352948188782], [0.7647058963775635], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.18431372940540314], [0.9921568632125854], [0.9882352948188782], [0.9137254953384399], [0.21960784494876862], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.6823529601097107], [0.9882352948188782], [0.9882352948188782], [0.6313725709915161], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4470588266849518], [0.9921568632125854], [0.9921568632125854], [0.8823529481887817], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4431372582912445], [0.9882352948188782], [0.9882352948188782], [0.6901960968971252], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.4431372582912445], [0.9882352948188782], [0.9882352948188782], [0.3294117748737335], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.3960784375667572], [0.9764705896377563], [0.8392156958580017], [0.10980392247438431], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.8823529481887817], [0.4627451002597809], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(image_to_predict.numpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-morgan",
   "metadata": {},
   "source": [
    "## Batch processing\n",
    "If we want, we can send multiple data samples for prediction. This is especially useful for batch processing workloads that might be running in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-fisher",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "        \"https://app.easytensor.com/query/\",\n",
    "        json={\n",
    "            \"instances\": [\n",
    "                # use the entireity of first batch\n",
    "                # make it a serializable list\n",
    "                image_batches[0].numpy().tolist()\n",
    "            ]\n",
    "        },\n",
    "        headers={\"accessToken\": access_token}\n",
    "    )\n",
    "predictions = np.array(response.json()[\"predictions\"])\n",
    "correct = 0\n",
    "for prediction, label in zip(\n",
    "    predictions.argmax(axis=1), label_batches[0]\n",
    "):\n",
    "    if prediction == label.numpy():\n",
    "        correct += 1\n",
    "print(\"{} Images were classified\".format(len(predictions)))\n",
    "print(\"Accuracy:\", correct/len(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
