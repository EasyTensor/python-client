{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "still-effectiveness",
   "metadata": {},
   "source": [
    "# PyTorch Text Classifier\n",
    "\n",
    "This notebook shows how to export a ðŸ¤—transformer model, upload it to easytensor, and query it on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install easytensor transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-consolidation",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "ðŸ¤—transformers make training a model rather easy but utilizing pre-trained models and allowing us to fine-tune them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MobileBertTokenizer, MobileBertModel\n",
    "\n",
    "model = MobileBertModel.from_pretrained(\"google/mobilebert-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-chicago",
   "metadata": {},
   "source": [
    "# Tokenizers\n",
    "\n",
    "We can use ðŸ¤— pre-trained tokenizers to preprocess our input and feed it directly into the model!\n",
    "\n",
    "Take note of the expansion of the input when it's passed to the model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MobileBertTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-works",
   "metadata": {},
   "source": [
    "# Uploading to EasyTensor\n",
    "\n",
    "Now that we have our model, We can upload it to EasyTensor. First, we create our model class definition and store it in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definition = \"\"\"\n",
    "# This is our model file.\n",
    "from transformers import MobileBertTokenizer, MobileBertModel, MobileBertConfig\n",
    "\n",
    "class MyModel(MobileBertModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        MobileBertModel.__init__(self, *args, **kwargs)\n",
    "        self.tokenizer = MobileBertTokenizer.from_pretrained(\n",
    "            \"google/mobilebert-uncased\"\n",
    "        )\n",
    "\n",
    "    def predict_single(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        outputs = self(**inputs)\n",
    "        return outputs[0].detach().numpy()[0].tolist()\n",
    "\"\"\"\n",
    "with open(\"model_file.py\", \"w\") as fout:\n",
    "    fout.write(model_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easytensor\n",
    "model_id, access_token = easytensor.transformers.upload_model(\"test_hf\", model, \"model_file.py\")\n",
    "print(\"model id:\", model_id, \"access code:\", access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-mistake",
   "metadata": {},
   "source": [
    "# Running Inference\n",
    "\n",
    "With the model uploaded to EasyTensor, you're now ready to run inference on the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.post(\n",
    "        \"https://app.easytensor.com/query/\",\n",
    "        json={\n",
    "            \"instances\": [\n",
    "                \"This is a test\"\n",
    "            ]\n",
    "        },\n",
    "        headers={\"accessToken\": access_token}\n",
    "    )\n",
    "response.raise_for_status()\n",
    "predictions = response.json()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-serial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
