{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "still-effectiveness",
   "metadata": {},
   "source": [
    "# PyTorch Text Classifier\n",
    "\n",
    "This notebook shows how to export a ðŸ¤—transformer model, upload it to easytensor, and query it on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brown-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (4.5.0)\n",
      "Requirement already satisfied: tqdm in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (4.58.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: sacremoses in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (0.0.44)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: requests in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: filelock in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: joblib in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /Users/kamalkamalaldin/virtualenv-3.8/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-consolidation",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "ðŸ¤—transformers make training a model rather easy but utilizing pre-trained models and allowing us to fine-tune them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absolute-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MobileBertTokenizer, MobileBertModel\n",
    "\n",
    "model = MobileBertModel.from_pretrained(\"google/mobilebert-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-chicago",
   "metadata": {},
   "source": [
    "# Tokenizers\n",
    "\n",
    "We can use ðŸ¤— pre-trained tokenizers to preprocess our input and feed it directly into the model!\n",
    "\n",
    "Take note of the expansion of the input when it's passed to the model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MobileBertTokenizer.from_pretrained(\"google/mobilebert-uncased\")\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-works",
   "metadata": {},
   "source": [
    "# Uploading to EasyTensor\n",
    "\n",
    "Now that we have our model, We can upload it to EasyTensor. First, we create our model class definition and store it in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "danish-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definition = \"\"\"\n",
    "# This is our model file.\n",
    "from transformers import MobileBertTokenizer, MobileBertModel, MobileBertConfig\n",
    "\n",
    "class MyModel(MobileBertModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        MobileBertModel.__init__(self, *args, **kwargs)\n",
    "        self.tokenizer = MobileBertTokenizer.from_pretrained(\n",
    "            \"google/mobilebert-uncased\"\n",
    "        )\n",
    "\n",
    "    def predict_single(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        outputs = self(**inputs)\n",
    "        return outputs[0].detach().numpy()[0].tolist()\n",
    "\"\"\"\n",
    "with open(\"model_file.py\", \"w\") as fout:\n",
    "    fout.write(model_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pending-glance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to EasyTensor: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87.2M/87.2M [01:59<00:00, 764kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246cfc9c-9ef7-458e-8a87-8941231a4c43 4f5ee90e-5356-4ff8-9b0d-033dabd357e0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import easytensor\n",
    "easytensor.set_base_url(\"http://127.0.0.1:8000\")\n",
    "model_id, access_token = easytensor.transformers.upload_model(\"test_hf\", model, \"model_file.py\")\n",
    "print(\"model id:\", model_id, \"access code:\", access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-mistake",
   "metadata": {},
   "source": [
    "# Running Inference\n",
    "\n",
    "With the model uploaded to EasyTensor, you're now ready to run inference on the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chubby-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.post(\n",
    "        \"http://localhost:8090/query/\",\n",
    "        json={\n",
    "            \"instances\": [\n",
    "                \"This is a test\"\n",
    "            ]\n",
    "        },\n",
    "        headers={\"accessToken\": access_token}\n",
    "    )\n",
    "predictions = np.array(response.json()[\"predictions\"])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
